graph LR
    %% --- STYLE DEFINITIONS ---
    classDef userNode fill:#2d3436,stroke:#000,stroke-width:0px,color:#fff,rx:5,ry:5;
    classDef frontend fill:#ffffff,stroke:#0984e3,stroke-width:2px,color:#2d3436,rx:10,ry:10;
    classDef perception fill:#e17055,stroke:#d63031,stroke-width:2px,color:#fff,rx:5,ry:5;
    classDef rag fill:#fdcb6e,stroke:#e1b12c,stroke-width:2px,color:#2d3436,rx:5,ry:5;
    classDef llm fill:#6c5ce7,stroke:#a29bfe,stroke-width:2px,color:#fff,rx:5,ry:5;
    classDef storage fill:#dfe6e9,stroke:#b2bec3,stroke-width:1px,stroke-dasharray: 5 5,color:#2d3436;

    %% --- NODES ---
    User((ðŸ‘¤ User)):::userNode
    
    subgraph UI ["ðŸ–¥ï¸ Presentation Layer"]
        App["Streamlit App"]:::frontend
    end

    subgraph Vision ["ðŸ‘ï¸ Perception Layer"]
        InputData{"Input Type"}:::storage
        CLIP["CLIP Vision Model"]:::perception
        OCR["Tesseract OCR"]:::perception
        Ingredients["Detected Ingredients"]:::perception
    end

    subgraph Logic ["ðŸ§  Intelligence Layer"]
        subgraph Knowledge ["Context Retrieval (RAG)"]
            VectorDB[("ChromaDB")]:::rag
            Retriever["Semantic Search"]:::rag
            Context["Verified Recipes"]:::rag
        end

        subgraph GenAI ["Generative Engine"]
            Prompt["Prompt Engineer"]:::llm
            Llama["Llama.cpp (CPU)"]:::llm
            Output["Structured Recipe"]:::llm
        end
    end

    %% --- FLOW ---
    User --> App
    App --> InputData
    
    %% Vision Flow
    InputData -- Image --> CLIP 
    InputData -- Image --> OCR
    InputData -- Text --> Ingredients
    CLIP --> Ingredients
    OCR --> Ingredients

    %% RAG Flow
    Ingredients --> Retriever
    Retriever <--> VectorDB
    Retriever --> Context

    %% Generation Flow
    Ingredients --> Prompt
    Context --> Prompt
    Prompt --> Llama
    Llama --> Output
    Output --> App

    %% --- LINKS ---
    linkStyle default stroke:#b2bec3,stroke-width:2px,fill:none;